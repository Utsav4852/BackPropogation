{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #import libraries\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actsig(z): #define sigmoid activation function\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lay(X, Y): #define input and output layer shape or no of inout and output nodes\n",
    "    \n",
    "    no_input = X.shape[0]\n",
    "    no_output = Y.shape[0]\n",
    "    return no_input, no_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(no_input, n_h1, n_h2, n_h3, no_output): #intialize weights and bisas at each layer\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.randn(n_h1, no_input) * 0.01    #weigth for inputlayer--->Hiddenlayer1\n",
    "    b1 = np.random.rand(n_h1, 1)                #bias for inputlayer--->Hiddenlayer1\n",
    "    W2 = np.random.rand(n_h2, n_h1)             #weight for hiddenlayer1---->HiddenLayer2\n",
    "    b2 = np.random.rand(n_h2, 1)                 #bias for hiddenlayer1---->HiddenLayer2\n",
    "    W3 = np.random.rand(n_h3, n_h2)             #weight for HiddenLayer2--->HiddenLayer3\n",
    "    b3 = np.random.rand(n_h3, 1)                #bias for  HiddenLayer2--->HiddenLayer3\n",
    "    W4 = np.random.rand(no_output, n_h3)        #weight for HiddenLayer3---->OutputLayer\n",
    "    b4 = np.random.rand(no_output, 1)         #bias for HiddenLayer3---->OutputLayer\n",
    "    para = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardpo(X, para):   #define Forward Prpogation\n",
    "    W1 = para['W1']\n",
    "    b1 = para['b1']\n",
    "    W2 = para['W2']\n",
    "    b2 = para['b2']\n",
    "    W3 = para['W3']\n",
    "    b3 = para['b3']\n",
    "    W4 = para['W4']\n",
    "    b4 = para['b4']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1    #Calculate output from inputlayer--->Hiddenlayer1\n",
    "    A1 = np.tanh(Z1)           #apply Activation Function at HiddenLayer1 and its input for Hidden1Layer1\n",
    "    Z2 = np.dot(W2, A1) + b2     #Calculate output from Hiddenlayer1--->Hiddenlayer2\n",
    "    A2 = np.tanh(Z2)            #apply Activation Function at HiddenLayer2 and its input for Hidden1Layer2\n",
    "    Z3 = np.dot(W3, A2) + b3   #Calculate output from Hiddenlayer2--->Hiddenlayer3\n",
    "    A3 = np.tanh(Z3)         #apply Activation Function at HiddenLayer3 and its input for Hidden1Layer3\n",
    "    Z4 = np.dot(W4, A3) + b4           #Calculate output from Hiddenlayer3--->OutputLayer\n",
    "    A4 = actsig(Z4)           #apply Activation Function atOutputLayer\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2,\n",
    "             \"Z3\": Z3,\n",
    "             \"A3\": A3,\n",
    "             \"Z4\": Z4,\n",
    "             \"A4\": A4}\n",
    "\n",
    "    return A4, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computcost(A4, Y, para):  #define Cost computation\n",
    "    m = Y.shape[1]\n",
    "    W1 = para['W1']\n",
    "    W2 = para['W2']\n",
    "    W3 = para['W3']\n",
    "    W4 = para['W4']\n",
    "    logprobs = np.multiply(np.log(A4), Y) + np.multiply(np.log(1 - A4), (1 - Y))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpro(para, cache, X, Y):  #define Backpropogation\n",
    "    m = Y.shape[1]\n",
    "    W1 = para['W1']\n",
    "    W2 = para['W2']\n",
    "    W3 = para['W3']\n",
    "    W4 = para['W4']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    A3 = cache['A3']\n",
    "    A4 = cache['A4']\n",
    "    \n",
    "    \n",
    "    dZ4 = A4 - Y       #Goto backword and with the derivative of output w.r.t weights find error in weight at every layer\n",
    "    dW4 = (1 / m) * np.dot(dZ4, A3.T)  #OutputLayer--->HiddenLayer3\n",
    "    db4 = (1 / m) * np.sum(dZ4, axis=1, keepdims=True)\n",
    "                           \n",
    "    dZ3 = np.multiply(np.dot(W4.T, dZ4), 1 - np.square(A3))  #HiddenLayer3--->HiddenLayer2\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "                           \n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.square(A2))  #HiddenLayer2--->HiddenLayer1\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.square(A1)) #HiddenLayer1--->InputLayer\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2,\n",
    "             \"dW3\": dW3,\n",
    "             \"db3\": db3,\n",
    "             \"dW4\": dW4,\n",
    "             \"db4\": db4}\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upd_para(para, grads, alpha):   #Update parameters Regarding Backpropogation\n",
    "    W1 = para['W1']\n",
    "    b1 = para['b1']\n",
    "    W2 = para['W2']\n",
    "    b2 = para['b2']\n",
    "    W3 = para['W3']\n",
    "    b3 = para['b3']\n",
    "    W4 = para['W4']\n",
    "    b4 = para['b4']\n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    dW3 = grads['dW3']\n",
    "    db3 = grads['db3']\n",
    "    dW4 = grads['dW4']\n",
    "    db4 = grads['db4']\n",
    "\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    W3 = W3 - alpha * dW3\n",
    "    b3 = b3 - alpha * db3\n",
    "    W4 = W4 - alpha * dW4\n",
    "    b4 = b4 - alpha * db4\n",
    "\n",
    "    para = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, n_h1, n_h2, n_h3, num_iters, alpha, print_cost): #Built Model To train and test dataset\n",
    "    np.random.seed(3)\n",
    "    no_input = lay(X, Y)[0]  #define No of nodes at input layer and output layer\n",
    "    no_output = lay(X, Y)[1]\n",
    "\n",
    "    para = init(no_input, n_h1, n_h2, n_h3, no_output)  # calll parametrs\n",
    "    W1 = para['W1']\n",
    "    b1 = para['b1']\n",
    "    W2 = para['W2']\n",
    "    b2 = para['b2']\n",
    "    W3 = para['W3']\n",
    "    b3 = para['b3']\n",
    "    W4 = para['W4']\n",
    "    b4 = para['b4']\n",
    "\n",
    "    costs = []\n",
    "    for i in range(0, num_iters): \n",
    "\n",
    "        A4, cache = forwardpo(X, para)  #call forawrd propogation function in range of num of iteration\n",
    "\n",
    "        cost = computcost(A4, Y, para)\n",
    "        grads = backpro(para, cache, X, Y)  #call backpropogation function\n",
    "        if (i > 20000):\n",
    "            alpha1 = (20000 / i) * alpha\n",
    "            para = upd_para(para, grads, alpha1) #call update pameter function\n",
    "        else:\n",
    "            para = upd_para(para, grads, alpha)\n",
    "\n",
    "       \n",
    "     \n",
    "    X_test = pd.read_csv('test_cancer_data.csv') #read dataset for testing\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.T\n",
    "    Y_test = pd.read_csv('test_cancer_data_y.csv')\n",
    "    Y_test = np.array(Y_test)\n",
    "    Y_test = Y_test.T\n",
    "\n",
    "    predictionions = prediction(para,  X)\n",
    "    print('Accuracy on training set: %.2f' % float(\n",
    "         (np.dot(Y, predictionions.T) + np.dot(1 - Y, 1 - predictionions.T)) / float(Y.size) * 100) + '%')\n",
    "  \n",
    "\n",
    "    predictionions = prediction(para, X_test)\n",
    "    print('Accuracy on test set: %.2f' % float(\n",
    "        (np.dot(Y_test, predictionions.T) + np.dot(1 - Y_test, 1 - predictionions.T)) / float(Y_test.size) * 100) + '%')\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(para, X): #define prediction\n",
    "    A4, cache = forwardpo(X, para)\n",
    "    predictionions = np.round(A4)\n",
    "\n",
    "    return predictionions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): #main method\n",
    "    traino_input = pd.read_csv('cancer_data.csv') #read training dataset\n",
    "    traino_input = np.array(traino_input)\n",
    "    traino_output = pd.read_csv('cancer_data_y.csv')\n",
    "    traino_output = np.array(traino_output)\n",
    "\n",
    "    d = model(traino_input.T, traino_output.T, n_h1=20, n_h2=30, n_h3=20, num_iters=50000, alpha=0.0002, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 76.51%\n",
      "Accuracy on test set: 57.89%\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
